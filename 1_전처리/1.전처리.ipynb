{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "preliminary-guest",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib/python3.6/site-packages/geopandas/_compat.py:91: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.0-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python-MIP package version 1.5.3\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import random\n",
    "from functools import reduce\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 공간연산한 결과 데이터 표현하기 위한 패키지 \n",
    "import folium\n",
    "from folium import plugins\n",
    "import shapely\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "import geopandas as gpd\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn.cluster\n",
    "import tensorflow as tf\n",
    "from geoband import API # API 부르기 \n",
    "import pydeck as pdk\n",
    "import os\n",
    "from tqdm import notebook\n",
    "import tqdm\n",
    "\n",
    "import cufflinks as cf \n",
    "cf.go_offline(connected=True)\n",
    "cf.set_config_file(theme='polar')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# 경고 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = 'Nanum Gothic'\n",
    "\n",
    "from shapely.geometry import Polygon, Point\n",
    "from numpy import random\n",
    "\n",
    "#최적화 solver\n",
    "import time\n",
    "from mip import Model, xsum, maximize, BINARY  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-track",
   "metadata": {},
   "source": [
    "### 결과보고서 같이 코드 참고\n",
    "\n",
    "## data load\n",
    "- data_list.csv : 제공 데이터를 목록화 한 datframe\n",
    "- file의 위치에 맞게 데이터를 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "raising-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노트북에서 만든 data_list load\n",
    "file_df = pd.read_csv(\"./data/data_list.csv\")\n",
    "\n",
    "# order_num type change int to str\n",
    "file_df[\"order_num\"] = file_df[\"order_num\"].apply(lambda x: str(x))\n",
    "\n",
    "# # data download\n",
    "# for i in range(len(file_df)):\n",
    "#     basic_code = 'SBJ_2102_002'\n",
    "#     num = i + 1\n",
    "#     file_name = \".\".join(file_df.iloc[i, :])\n",
    "#     GetCompasData(basic_code, str(num), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unlike-stopping",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [08:11<00:00, 15.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# 동적변수 데이터 할당\n",
    "# load한 데이터를 : df_1, df_2 ...., df_32로 할당\n",
    "for idx in tqdm.tqdm(range(len(file_df) - 2)):\n",
    "#     print(idx)\n",
    "    file_name = \".\".join(file_df.iloc[idx, :])\n",
    "    globals()[f\"df_{idx + 1}\"] = gpd.read_file(\"./data/\" + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-superior",
   "metadata": {},
   "source": [
    "### df_500 : 기준 ID\n",
    "- 정류장 ID와 정류소 ID를 비교를 통해 기준이 되는 ID 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "accessory-dollar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정류소에 속하지 않은 정류장 수 : 51, 정류장에 속하지 않은 정류소 수 : 0\n"
     ]
    }
   ],
   "source": [
    "# 기준 ID 선정\n",
    "bus_bay = df_1[\"정류장ID\"].unique()\n",
    "bus_stop = df_7[\"정류소ID\"].unique()\n",
    "\n",
    "bay_not_in_stop = []\n",
    "stop_not_in_bay = []\n",
    "\n",
    "for bay in bus_bay:\n",
    "    if bay not in bus_stop:\n",
    "        bay_not_in_stop.append(bay)\n",
    "        \n",
    "for stop in bus_stop:\n",
    "    if stop not in bus_bay:\n",
    "        stop_not_in_bay.append(stop)\n",
    "        \n",
    "print(f\"정류소에 속하지 않은 정류장 수 : {len(bay_not_in_stop)}, 정류장에 속하지 않은 정류소 수 : {len(stop_not_in_bay)}\")\n",
    "# 정류소에 속하지 않은 정류장 수가 많으므로 정류장ID를 기준으로 위도(latitude) 경도(longitude) 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "legitimate-cameroon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기준 이력은 (1) 468\n",
      "승하차이력(2)에 속하지 않는 ID가 있다. 133\n",
      "승하차이력(3)에 속하지 않는 ID가 있다. 145\n",
      "승하차이력(4)에 속하지 않는 ID가 있다. 107\n",
      "승하차이력(5)에 속하지 않는 ID가 있다. 186 \n",
      "\n",
      "승하차이력(1)에 속하지 않는 ID가 있다. 214\n",
      "기준 이력은 (2) 549\n",
      "승하차이력(3)에 속하지 않는 ID가 있다. 185\n",
      "승하차이력(4)에 속하지 않는 ID가 있다. 124\n",
      "승하차이력(5)에 속하지 않는 ID가 있다. 261 \n",
      "\n",
      "승하차이력(1)에 속하지 않는 ID가 있다. 439\n",
      "승하차이력(2)에 속하지 않는 ID가 있다. 398\n",
      "기준 이력은 (3) 762\n",
      "승하차이력(4)에 속하지 않는 ID가 있다. 238\n",
      "승하차이력(5)에 속하지 않는 ID가 있다. 377 \n",
      "\n",
      "승하차이력(1)에 속하지 않는 ID가 있다. 389\n",
      "승하차이력(2)에 속하지 않는 ID가 있다. 325\n",
      "승하차이력(3)에 속하지 않는 ID가 있다. 226\n",
      "기준 이력은 (4) 750\n",
      "승하차이력(5)에 속하지 않는 ID가 있다. 312 \n",
      "\n",
      "승하차이력(1)에 속하지 않는 ID가 있다. 251\n",
      "승하차이력(2)에 속하지 않는 ID가 있다. 245\n",
      "승하차이력(3)에 속하지 않는 ID가 있다. 148\n",
      "승하차이력(4)에 속하지 않는 ID가 있다. 95\n",
      "기준 이력은 (5)\n",
      " 533\n"
     ]
    }
   ],
   "source": [
    "# 승하차이력 데이터 정류소 중복 확인\n",
    "# why? df과 서로 중복이 되는 정류소 ID를 확인하기 위해\n",
    "\n",
    "stop_id_1 = df_2[\"정류소ID\"].unique()\n",
    "stop_id_2 = df_3[\"정류소ID\"].unique()\n",
    "stop_id_3 = df_4[\"정류소ID\"].unique()\n",
    "stop_id_4 = df_5[\"정류소ID\"].unique()\n",
    "stop_id_5 = df_6[\"정류소ID\"].unique()\n",
    "lst = [stop_id_1, stop_id_2, stop_id_3, stop_id_4, stop_id_5]\n",
    "\n",
    "# 버스정류장별_승하차이력 별 속하지 않는 정류소id 확인\n",
    "def check_duplicate(x):\n",
    "    \n",
    "    check_1 = []\n",
    "    check_2 = []\n",
    "    check_3 = []\n",
    "    check_4 = []\n",
    "    check_5 = []\n",
    "\n",
    "    for id in x:\n",
    "        if id not in stop_id_1:\n",
    "            check_1.append(id)\n",
    "        if id not in stop_id_2:\n",
    "            check_2.append(id)\n",
    "        if id not in stop_id_3:\n",
    "            check_3.append(id)\n",
    "        if id not in stop_id_4:\n",
    "            check_4.append(id)\n",
    "        if id not in stop_id_5:\n",
    "            check_5.append(id)\n",
    "\n",
    "    if len(check_1) > 0:\n",
    "        print(\"승하차이력(1)에 속하지 않는 ID가 있다.\", len(check_1))\n",
    "    else:\n",
    "        print(\"기준 이력은 (1)\", len(x))\n",
    "    if len(check_2) > 0:\n",
    "        print(\"승하차이력(2)에 속하지 않는 ID가 있다.\", len(check_2))\n",
    "    else:\n",
    "        print(\"기준 이력은 (2)\", len(x))\n",
    "    if len(check_3) > 0:\n",
    "        print(\"승하차이력(3)에 속하지 않는 ID가 있다.\", len(check_3))\n",
    "    else:\n",
    "        print(\"기준 이력은 (3)\", len(x))\n",
    "    if len(check_4) > 0:\n",
    "        print(\"승하차이력(4)에 속하지 않는 ID가 있다.\", len(check_4))\n",
    "    else:\n",
    "        print(\"기준 이력은 (4)\", len(x))\n",
    "    if len(check_5) > 0:\n",
    "        print(\"승하차이력(5)에 속하지 않는 ID가 있다.\", len(check_5), \"\\n\")\n",
    "    else:\n",
    "        print(\"기준 이력은 (5)\\n\", len(x))\n",
    "        \n",
    "for x in lst:\n",
    "    check_duplicate(x)\n",
    "    \n",
    "# 승하차이력마다 겹치는 정류소ID가 있으므로 df_1의 정류장ID를 기준으로 합한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-carroll",
   "metadata": {},
   "source": [
    "### df_500 : 훈련 데이터 셋 기준 df 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "charitable-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 승하차 관련 변수 추가\n",
    "get_in_out_lst = df_2.iloc[0, 6:-1].index.values\n",
    "\n",
    "for col in get_in_out_lst:\n",
    "    df_1[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "starting-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 승하차 관련 변수 타입 변경\n",
    "def change_dtype(df):\n",
    "    for col in get_in_out_lst:\n",
    "        df[col] = df[col].astype(int)\n",
    "        \n",
    "df_lst = [df_2, df_3, df_4, df_5, df_6]\n",
    "for df in df_lst:\n",
    "    change_dtype(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "affecting-latex",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1179/1179 [00:01<00:00, 758.85it/s]\n",
      "100%|██████████| 1179/1179 [00:01<00:00, 622.79it/s]\n",
      "100%|██████████| 1179/1179 [00:02<00:00, 523.88it/s]\n",
      "100%|██████████| 1179/1179 [00:02<00:00, 483.31it/s]\n",
      "100%|██████████| 1179/1179 [00:01<00:00, 725.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# 승하차 변수 더하기\n",
    "def add_get_in_out(criterion, add_df):\n",
    "    for idx in tqdm.tqdm(range(len(criterion))):\n",
    "        id = criterion.iloc[idx, 0]\n",
    "        \n",
    "        check_index = add_df.index.values\n",
    "        if id in check_index:\n",
    "            for col in get_in_out_lst:\n",
    "                criterion.loc[idx, col] += add_df.loc[id, col]\n",
    "                    \n",
    "                    \n",
    "for add_df in df_lst:\n",
    "    add_df = add_df.groupby(\"정류소ID\")[get_in_out_lst].agg(\"sum\")\n",
    "    add_get_in_out(df_1, add_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "tested-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500m 기준 TOD 변수들을 뽑기 위해 point 기준 500m 버퍼 생성\n",
    "\n",
    "# point 생성\n",
    "# geopandas의 gis 관련 함수를 사용하기 위해서는 기준이 되는 point, polygon과 같은\n",
    "# geometry타입의 변수가 있어야 된다.\n",
    "geometry = gpd.points_from_xy(df_1.lon, df_1.lat)\n",
    "# point 할당\n",
    "df_1[\"geometry\"] = geometry\n",
    "# 1m\n",
    "coor_1m = (1/88.74/1000)\n",
    "#500m 버퍼 생성\n",
    "df_1[\"buffer\"] = df_1[\"geometry\"].apply(lambda x: x.buffer(coor_1m*500))\n",
    "\n",
    "df_1.to_csv(\"수원시_버스정류장_승하차이력.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-siemens",
   "metadata": {},
   "source": [
    "### 지하철 역 수 도출을 위한 df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 추출\n",
    "subway_col = df_9.iloc[0, 5:-1].index.values\n",
    "\n",
    "# , 제거 후 int형으로 변경\n",
    "def remove(x):\n",
    "    x = x.replace(\",\", \"\")\n",
    "    return x\n",
    "\n",
    "for i in subway_col:\n",
    "    df_9[i] = df_9[i].apply(lambda x: remove(x))\n",
    "    df_9[i] = df_9[i].astype(int)\n",
    "    \n",
    "subway_sum_df = df_9.groupby([\"역명\", \"승하차\"])[subway_col].agg(\"sum\").reset_index()\n",
    "\n",
    "subway_sum_df[\"lon\"] = 0\n",
    "subway_sum_df[\"lat\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "addressed-field",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수원\n",
      "수원\n"
     ]
    }
   ],
   "source": [
    "# 역별 경도 위도 부여\n",
    "for idx in range(len(subway_sum_df)):\n",
    "    subway_id = subway_sum_df.iloc[idx, 0]\n",
    "    try:\n",
    "        subway_sum_df.loc[idx, \"lon\"] = df_8[df_8[\"역사명\"] == subway_id][\"lon\"].values\n",
    "        subway_sum_df.loc[idx, \"lat\"] = df_8[df_8[\"역사명\"] == subway_id][\"lat\"].values\n",
    "    except Exception as e:\n",
    "        print(subway_id)\n",
    "        \n",
    "# 기준 id가 달라서 부여 되지 않은 경도 위도 추출 후 부여\n",
    "lon = df_8[df_8[\"역사명\"] == \"수원역\"][\"lon\"].values\n",
    "lat = df_8[df_8[\"역사명\"] == \"수원역\"][\"lat\"].values\n",
    "\n",
    "subway_sum_df.loc[10, \"lon\"] = lon\n",
    "subway_sum_df.loc[10, \"lat\"] = lat\n",
    "subway_sum_df.loc[11, \"lon\"] = lon\n",
    "subway_sum_df.loc[11, \"lat\"] = lat\n",
    "\n",
    "# geometry point 생성\n",
    "geometry = gpd.points_from_xy(subway_sum_df.lon, subway_sum_df.lat)\n",
    "subway_sum_df[\"geometry\"] = geometry\n",
    "\n",
    "\n",
    "subway_sum_df.to_csv(\"수원시_지하철역별_이용현황.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-assessment",
   "metadata": {},
   "source": [
    "### 유동인구 - 인구정보 결합데이터 추출\n",
    "- 유동인구 병합데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "rural-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계산을 위해 dtype 변환\n",
    "df_14.iloc[:, 1:-3] = df_14.iloc[:, 1:-3].astype(float)\n",
    "df_15.iloc[:, 1:-3] = df_15.iloc[:, 1:-3].astype(float)\n",
    "df_16.iloc[:, 1:-3] = df_16.iloc[:, 1:-3].astype(float)\n",
    "\n",
    "# 경도 위도 데이터 타입 변환 why? string 형태에서 1480 과 148을 다른것으로 인식하기 때문\n",
    "def dtype_change(x):\n",
    "    x[\"lon\"] = x[\"lon\"].astype(float)\n",
    "    x[\"lat\"] = x[\"lat\"].astype(float)\n",
    "    \n",
    "pop_lst = [df_14, df_15, df_16]\n",
    "\n",
    "for df in pop_lst:\n",
    "    dtype_change(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "decreased-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유동인구 변수를 추출하기 위해 버스 이용가능 시간인 06 ~ 23시까지 indexing하고 합한 뒤\n",
    "df_14[\"sum_pop\"] = df_14.loc[:, \"TMST_06\":\"TMST_23\"].agg(\"sum\", axis = 1).values\n",
    "\n",
    "# 1 ~ 12월의 평균값 도출\n",
    "df_pop = df_14.groupby([\"lon\", \"lat\"])[\"sum_pop\"].agg(['sum',\n",
    "                                                       \"mean\"]).rename({\"mean\":\"pop\"}, axis = 1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "parental-shooting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0350</td>\n",
       "      <td>126.927348</td>\n",
       "      <td>37.278703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.2810</td>\n",
       "      <td>126.927389</td>\n",
       "      <td>37.273295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.8575</td>\n",
       "      <td>126.927392</td>\n",
       "      <td>37.272844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1420</td>\n",
       "      <td>126.927395</td>\n",
       "      <td>37.272393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0870</td>\n",
       "      <td>126.927399</td>\n",
       "      <td>37.271943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pop         lon        lat\n",
       "0  0.0350  126.927348  37.278703\n",
       "1  3.2810  126.927389  37.273295\n",
       "2  4.8575  126.927392  37.272844\n",
       "3  1.1420  126.927395  37.272393\n",
       "4  2.0870  126.927399  37.271943"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pop = df_pop[[\"pop\", \"lon\", \"lat\"]]\n",
    "df_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 변수 추출\n",
    "# 광고 Targets에 할용 될 변수\n",
    "col_15 = df_15.iloc[:, 1:-3].columns.values\n",
    "\n",
    "# 경도 위도 기준 변수 별 평균 도출\n",
    "# 병합에 사용될 df \n",
    "df_15_crit = df_15.groupby([\"lon\", \"lat\"])[col_15].agg(\"mean\").reset_index()\n",
    "\n",
    "# 참고할 df 추출\n",
    "col_16 = df_16.iloc[:, 1:-3].columns.values\n",
    "df_16_crit = df_16.groupby([\"lon\", \"lat\"])[col_16].agg(\"mean\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "developed-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유동인구 데이터들은 수원시를 50m x 50m격자를 기준으로 제공 되기 때문에\n",
    "# 기준 경도 위도 추출을 통해 데이터 병합에 사용\n",
    "crit_pop = df_pop[[\"lon\", \"lat\"]]\n",
    "crit_15 = df_15_crit[[\"lon\", \"lat\"]]\n",
    "crit_16 = df_16_crit[[\"lon\", \"lat\"]]\n",
    "df_new_2 = pd.concat([crit_pop, crit_15, crit_16]).reset_index(drop = True)\n",
    "\n",
    "# groupby에 사용할 임시 변수 추가\n",
    "df_new_2[\"pop\"] = 0\n",
    "\n",
    "# 기준 경도 위도 추출\n",
    "df_new_2 = df_new_2.groupby([\"lon\", \"lat\"])[\"pop\"].agg([\"count\", \"mean\"]).reset_index()[[\"lon\", \"lat\"]]\n",
    "\n",
    "# 필요 변수 추가\n",
    "df_new_2[\"pop\"] = 0\n",
    "df_new_2[col_15] = 0\n",
    "df_new_2[col_16] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기준 경도 위도에 데이터 할당\n",
    "# try: except를 예외처리를 한 이유?\n",
    "# 기준이 되는 위도 경도를 뽑았지만 제공되는 유동인구 데이터 별 \n",
    "# 제공하는 데이터 포인트가 다르기 때문에 기준이 되는 위도 경도에 해당하는 데이터가\n",
    "# 결측치일 때 오류를 방지하고 for문을 돌리기 위해\n",
    "for idx in tqdm.tqdm(range(len(df_new_2))):\n",
    "    try:\n",
    "        pop = df_pop[(df_pop[\"lon\"] == df_new_2.loc[idx, \"lon\"]) &\n",
    "                (df_pop[\"lat\"] == df_new_2.loc[idx, \"lat\"])][\"pop\"].values\n",
    "        df_new_2.loc[idx, \"pop\"] = pop\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"시간대별 유동인구 오류 :\", idx, e)\n",
    "        \n",
    "    try:\n",
    "        sex_pop = df_15_crit[(df_15_crit[\"lon\"] == df_new_2.loc[idx, \"lon\"]) &\n",
    "                (df_15_crit[\"lat\"] == df_new_2.loc[idx, \"lat\"])][col_15].values[0]\n",
    "        df_new_2.loc[idx, col_15] = sex_pop\n",
    "    except Exception as e:\n",
    "        print(\"성연령별 유동인구 오류 :\", idx, e)\n",
    "\n",
    "    try:\n",
    "        day_pop = df_16_crit[(df_16_crit[\"lon\"] == df_new_2.loc[idx, \"lon\"]) &\n",
    "                (df_16_crit[\"lat\"] == df_new_2.loc[idx, \"lat\"])][col_16].values[0]\n",
    "        df_new_2.loc[idx, col_16] = day_pop\n",
    "    except Exception as e:\n",
    "        print(\"요일별 유동인구 오류 :\", idx, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "higher-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유동인구 데이터 geometry생성\n",
    "# geopandas 함수 사용을 위해\n",
    "def make_geometry_point(df):\n",
    "    geometry = gpd.points_from_xy(df.lon, df.lat)\n",
    "    df[\"geometry\"] = geometry    \n",
    "\n",
    "make_geometry_point(df_new_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-accountability",
   "metadata": {},
   "source": [
    "- 인구정보 병합데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "composed-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인구정보 결측치 채우기\n",
    "df_17.fillna(0, inplace = True)\n",
    "df_18.fillna(0, inplace = True)\n",
    "df_19.fillna(0, inplace = True)\n",
    "df_28.fillna(0, inplace = True)\n",
    "\n",
    "old_val = df_17[\"val\"]\n",
    "worker_val = df_18[\"val\"]\n",
    "youth_val = df_19[\"val\"]\n",
    "building_area = df_28[\"val\"]\n",
    "\n",
    "# 기준이 되는 인구정보 df\n",
    "df_new = pd.DataFrame({\"gid\":df_17[\"gid\"], \"old\":old_val,\n",
    "                      \"worker\":worker_val, \"youth\":youth_val, \"building_area\":building_area\n",
    "                       ,\"geometry\":df_17[\"geometry\"]})\n",
    "\n",
    "df_new.to_csv(\"격자_데이터.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "nominated-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sjoin(spatial join을 위해 ) df -> geodf\n",
    "# 인구정보 df\n",
    "df_new = gpd.GeoDataFrame(df_new)\n",
    "# 유동인구 df\n",
    "crit = gpd.GeoDataFrame(df_new_2)\n",
    "\n",
    "# sjoin을 통합 병합\n",
    "check_df = gpd.sjoin(df_new, crit, op = \"contains\", how = \"left\")\n",
    "\n",
    "# 구해야 되는 변수 \n",
    "col_human = df_new.iloc[0, 1:-1].index.values\n",
    "col_pop = crit.iloc[0, 2:-1].index.values\n",
    "\n",
    "# 인구정보 : 평균 (result :이전 값 그대로)\n",
    "human_df = check_df.groupby(\"gid\")[col_human].agg(\"mean\").reset_index()\n",
    "# 유동인구 : 합계 (gid 격자안에 속하는 값 모두 더하기)\n",
    "pop_df = check_df.groupby(\"gid\")[col_pop].agg(\"sum\").reset_index()\n",
    "\n",
    "# gid 기준으로 병합\n",
    "final_df = pd.merge(human_df, pop_df, on=\"gid\")\n",
    "\n",
    "# 기존 폴리곤 부여(why? 시각화와 sjoin에 쓰기 위해)\n",
    "final_df[\"geometry\"] = df_new[\"geometry\"]\n",
    "\n",
    "final_df.to_csv(\"유동인구_인구정보_결합.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-clone",
   "metadata": {},
   "source": [
    "### 도로 데이터 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full time 제외 버스 운영 시간으로 필터링\n",
    "traffic_crit_df = df_23[df_23[\"시간적범위\"] != \"fulltime\"].reset_index(drop = True)\n",
    "# 계산 하기 위해 dtype 변경\n",
    "traffic_crit_df.iloc[:, 7:-1] = traffic_crit_df.iloc[:, 7:-1].astype(int)\n",
    "# 버스 운행 시간 필터링\n",
    "traffic_crit_df = traffic_crit_df[(traffic_crit_df[\"시간적범위\"] >= 6)].reset_index(drop = True, inplace = True)\n",
    "\n",
    "# 사용할 변수 추출\n",
    "traffic_col = traffic_crit_df.iloc[:, 8:-1].columns.values\n",
    "# linkid기준 그룹핑 후 변수로 합계 추출\n",
    "traffic_df = traffic_crit_df.groupby(\"상세도로망_LinkID\")[traffic_col].agg(\"sum\").reset_index()\n",
    "# 기준 df 추출\n",
    "traffic_crit_df_subset = traffic_crit_df.drop_duplicates(subset = \"상세도로망_LinkID\", keep = \"last\").reset_index(drop = True).iloc[:, :7]\n",
    "# 병합 주의사항) 전체_추정교통량은 승용차 + 버스 + 화물차랑 약간씩 다른 경우가 있다.\n",
    "df_new_3 = pd.merge(traffic_df, traffic_crit_df_subset, on = \"상세도로망_LinkID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "colored-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_23 24 병합\n",
    "df_24_25 = pd.merge(df_24, df_25.iloc[:, [0, -2]], on = \"상세도로망_LinkID\")\n",
    "# 불필요 변수 제거\n",
    "df_24_25 = df_24_25.drop(\"geometry\", axis = 1)\n",
    "# 필수 df slicing\n",
    "df_24_25_subset = df_24_25.iloc[:, [0,-1,-2]]\n",
    "# df_23_24, df_new_3 병합 why left? df_new_3이 데이터 포인트가 많기 때문\n",
    "df_new_3_crit = pd.merge(df_new_3, df_24_25_subset, on = \"상세도로망_LinkID\", how = \"left\")\n",
    "\n",
    "re_col = ['상세도로망_LinkID', '도로등급', '링크길이', '도로명', '시도명', '시군구명', '읍면동명', '전체_추정교통량', '승용차_추정교통량',\n",
    "          '버스_추정교통량', '화물차_추정교통량', '혼잡시간강도', '혼잡빈도강도']\n",
    "\n",
    "# df_new_3_crit 순서 재정렬\n",
    "df_new_3_crit = df_new_3_crit[re_col]\n",
    "\n",
    "road_geo = df_22.iloc[:, [0, -1]]\n",
    "df_new_3_crit[\"link_id\"] = df_new_3_crit[\"상세도로망_LinkID\"].apply(lambda x: x[:-2])\n",
    "\n",
    "# 도로 데이터 병합\n",
    "road_transport_geo = pd.merge(df_new_3_crit, road_geo, how = \"left\")\n",
    "road_transport_geo.to_csv(\"./data/road_transport.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-cameroon",
   "metadata": {},
   "source": [
    "### 토지이용특성 변수 도출\n",
    "- 제공하는 코드명에 직접 설정한 변수명 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "apart-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 건물 데이터 중 slicing\n",
    "build_df = df_27.iloc[:, [0,-1]]\n",
    "# dtype 변경 why? bhilding_code랑 비교 하기 위해\n",
    "build_df[\"BDTYP_CD\"] = build_df[\"BDTYP_CD\"].astype(float)\n",
    "\n",
    "# 코드정의서 중 건물용도코드 부분에 직접 변수명 설정\n",
    "building_code = pd.read_csv(\"./data/건물용도코드_확인_필요.csv\")\n",
    "building_code.dropna(axis = 0, inplace = True)\n",
    "\n",
    "build_df[\"purpose\"] = 0\n",
    "\n",
    "for idx in range(len(building_code)):\n",
    "    try:\n",
    "        index = build_df[build_df[\"BDTYP_CD\"] == building_code.iloc[idx, 0]].index.values\n",
    "        build_df.iloc[index, -1] = building_code.iloc[idx, 1]\n",
    "    except:\n",
    "        print(idx)\n",
    "        \n",
    "        \n",
    "# 결측치 채우기\n",
    "fill_col = build_df[build_df[\"purpose\"] == 0][\"BDTYP_CD\"].unique()\n",
    "fill_col.sort()\n",
    "\n",
    "fill_lst = [\"문화체육시설\", \"공공시설\", \"공공시설\", \"공공시설\", \"공공시설\", \"공공시설\", \"공공시설\", \"공공시설\",\n",
    "      \"공공시설\", \"공공시설\", \"공공시설\", \"상업시설\", \"공공시설\", \"상업시설\", \"상업시설\", \"문화체육시설\",\n",
    "      \"상업시설\", \"상업시설\", \"문화체육시설\", \"상업시설\"]\n",
    "\n",
    "fill_df = pd.DataFrame({\"코드\":fill_col, \"변수\":fill_lst})\n",
    "new_building_code = pd.concat([building_code, fill_df]).reset_index(drop = True)\n",
    "\n",
    "\n",
    "for idx in range(len(new_building_code)):\n",
    "    try:\n",
    "        index = build_df[build_df[\"BDTYP_CD\"] == new_building_code.iloc[idx, 0]].index.values\n",
    "        build_df.iloc[index, -1] = new_building_code.iloc[idx, 1]\n",
    "    except:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-fluid",
   "metadata": {},
   "source": [
    "## 기준 df\n",
    "- df_500 : 버스정류장 위치 기준 반경 500m의 버퍼를 통해 TOD 변수들을 뽑은 훈련 데이터 셋\n",
    "- df_100 : 100m 격자인 gid를 기준으로 TOD 변수들은 뽑은 데이터로서 수원시의 특성을 파악하기 위해 사용\n",
    "- df_100_to_500 : 100m 격자의 중심점 기준 반경 500m의 버퍼를 통해 TOD 변수들을 뽑은 테스트 데이터 셋으로서 실제 입지선정에 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-fellow",
   "metadata": {},
   "source": [
    "### df_500 데이터 추출\n",
    "- 버스정류장 별 반경 500m 버펑 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "desperate-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection을 위해 buffer slicing 후 geometry로 컬럼명 변경\n",
    "df_1_area = df_1.loc[:, [\"정류장ID\", \"buffer\"]].rename({\"buffer\":\"geometry\"}, axis = 1)\n",
    "\n",
    "# df_1_area를 기준으로 buil_df intersection\n",
    "bus_with_build_area_df = gpd.overlay(df_1_area, build_df, how = \"intersection\")\n",
    "\n",
    "# 건물면적 구하기\n",
    "bus_with_build_area_df[\"area\"] = bus_with_build_area_df.area\n",
    "\n",
    "# 정류장 ID와 건물분류별 면적 합하기\n",
    "build_area = bus_with_build_area_df.groupby([\"정류장ID\", \"purpose\"])[\"area\"].agg(\"sum\").reset_index()\n",
    "\n",
    "# pivot table 활용하여 정류장ID별 건물불류 변수 table 생성\n",
    "table = pd.pivot_table(build_area, values = \"area\", index = \"정류장ID\", columns = \"purpose\").reset_index()\n",
    "\n",
    "# 결측치 처리\n",
    "table = table.fillna(0)\n",
    "\n",
    "# # 500m 버퍼 내의 면적을 구하기 위해 500m 버퍼 면적 구하기(면적)\n",
    "# denominator = df_1_area[df_1_area[\"정류장ID\"] == '201000266'].area.values[0]\n",
    "\n",
    "# #  intersection / 500m 면적\n",
    "# # table.iloc[:, 1:] = table.iloc[:, 1:].apply(lambda x: x / denominator)\n",
    "\n",
    "# 버퍼 내 전체 건물 면적 구하기\n",
    "table[\"건물면적\"] = table.iloc[:, 1:].sum(axis = 1)\n",
    "\n",
    "# 서버가 끊기는 것을 고려하여 저장하여 사용\n",
    "bus_with_build_area_df.to_csv(\"./data/500_build_polygon.csv\", index = False)\n",
    "\n",
    "# 500m 버스정류장, area 병합\n",
    "# 토지이용특성을 부여할 기준 df\n",
    "df_1_build = pd.merge(df_1, table, how = \"left\")\n",
    "\n",
    "df_1_build.to_csv(\"정류장_빌딩_병합.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-seminar",
   "metadata": {},
   "source": [
    "- 토지용특성 변수 추출(인구사회특성의 주거 연면적도 같이 추출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "phantom-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_build_crit = df_1_build.loc[:, [\"정류장ID\", \"buffer\"]].rename({\"buffer\":\"geometry\"}, axis = 1)\n",
    "\n",
    "# df_1_build_pop sjoin(default : \"intersection\")\n",
    "df_1_build_pop_final_inter = gpd.overlay(df_1_build_crit, final_df, how = \"intersection\")\n",
    "\n",
    "# 기준 면적(100mx100m 격자)\n",
    "crit_area = final_df[\"geometry\"].area\n",
    "\n",
    "# 가중치 구하기\n",
    "df_1_build_pop_final_inter[\"coef\"] = df_1_build_pop_final_inter[\"geometry\"].area / crit_area\n",
    "\n",
    "\n",
    "# 합계 필요한 변수 추출\n",
    "df_1_build_pop_final_inter_col = df_1_build_pop_final_inter.iloc[:, 2:-2].columns.values\n",
    "\n",
    "# 가중치 부여\n",
    "for idx in range(len(df_1_build_pop_final_inter_col)):\n",
    "    df_1_build_pop_final_inter[df_1_build_pop_final_inter_col[idx]] = df_1_build_pop_final_inter[df_1_build_pop_final_inter_col[idx]].mul(df_1_build_pop_final_inter[\"coef\"])\n",
    "\n",
    "# 정류장ID 기준으로 합계\n",
    "df_1_buil_pop_final_group = df_1_build_pop_final_inter.groupby(\"정류장ID\")[df_1_build_pop_final_inter_col].agg('sum').reset_index()\n",
    "\n",
    "# 병합\n",
    "df_1_build_pop = pd.merge(df_1_build, df_1_buil_pop_final_group, on = \"정류장ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-sigma",
   "metadata": {},
   "source": [
    "- 지하철역 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fitting-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = gpd.points_from_xy(df_8.lon, df_8.lat)\n",
    "df_8[\"geometry\"] = geometry\n",
    "\n",
    "# 지하철역 수\n",
    "ex = gpd.sjoin(df_1_build_pop.loc[:, [\"정류장ID\",\"buffer\"]].rename({\"buffer\":\"geometry\"}, axis = 1), df_8, how = 'inner', op = \"contains\")\n",
    "# 지하철역 수 count\n",
    "ex = ex[\"정류장ID\"].value_counts().reset_index().rename({\"index\":\"정류장ID\", \"정류장ID\":\"지하철역수\"}, axis = 1)\n",
    "\n",
    "# df_1_build_pop에 subway 병합\n",
    "df_1_build_pop_subway = pd.merge(df_1_build_pop, ex, how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-grove",
   "metadata": {},
   "source": [
    "- 버스정류장 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "twelve-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버스정류장\n",
    "# df_1_build_pop(버스정류장 버퍼)\n",
    "bus_buffer = df_1_build_pop\n",
    "\n",
    "# 버스정류장 point\n",
    "bus_point = df_1_build_pop_subway.loc[:, [\"정류장ID\", \"geometry\"]]\n",
    "\n",
    "# 버스정류장 수 구하기\n",
    "bus_count = gpd.sjoin(bus_buffer, bus_point, \"inner\", op = \"contains\")[\"정류장ID_left\"].value_counts()\n",
    "\n",
    "# 버스정류장 칼럼 명 변경\n",
    "bus_count = bus_count.reset_index().rename({\"index\":\"정류장ID\", \"정류장ID_left\":\"버스정류장수\"}, axis = 1)\n",
    "\n",
    "# 병합\n",
    "df_1_build_pop_subway_bus = pd.merge(df_1_build_pop_subway, bus_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-israel",
   "metadata": {},
   "source": [
    "- 주차장 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "informal-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주차장\n",
    "df_12.drop(\"geometry\", axis = 1, inplace = True)\n",
    "\n",
    "# 주차장 point 구하기\n",
    "geometry = gpd.points_from_xy(df_12.lon, df_12.lat)\n",
    "df_12[\"geometry\"] = geometry\n",
    "\n",
    "# 주차장수 구하기\n",
    "park_lot = gpd.sjoin(df_1_build_pop_subway_bus.loc[:, [\"정류장ID\", \"buffer\"]].rename({\"buffer\":\"geometry\"}, axis = 1), df_12, op = \"contains\")[\"정류장ID\"].value_counts()\n",
    "park_lot = park_lot.reset_index().rename({\"index\":\"정류장ID\", \"정류장ID\":\"주차장수\"}, axis = 1)\n",
    "\n",
    "# 주차장 수 병합\n",
    "df_1_build_pop_subway_bus_park = pd.merge(df_1_build_pop_subway_bus, park_lot, how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-luxury",
   "metadata": {},
   "source": [
    "- 접근성(거리) : 버스정류장 기준점과 각 건물의 중심점의 직선거리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "detected-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 접근성\n",
    "center = bus_with_build_area_df[\"geometry\"].centroid\n",
    "bus_with_build_area_df[\"center\"] = center\n",
    "build_df[\"center\"] = build_df[\"geometry\"].centroid\n",
    "df_1_buffer = df_1.loc[:, [\"정류장ID\", \"buffer\",\"geometry\"]].rename({\"geometry\":\"bus_center\", \"buffer\":\"geometry\"}, axis = 1)\n",
    "\n",
    "bus_with_build_area_df = gpd.overlay(df_1_buffer, build_df, how = \"intersection\")\n",
    "    \n",
    "    \n",
    "# 거리 구하기\n",
    "bus_with_build_area_df[\"distance\"] = 0\n",
    "\n",
    "dis = bus_with_build_area_df[\"center\"].distance(bus_with_build_area_df[\"bus_center\"])\n",
    "bus_with_build_area_df[\"distance\"] = dis\n",
    "    \n",
    "# 거리 평균\n",
    "bus_build_distance = bus_with_build_area_df.groupby(\"정류장ID\")[\"distance\"].agg(\"mean\").reset_index()\n",
    "\n",
    "# 병합\n",
    "df_1_build_pop_subway_bus_park_acc = pd.merge(df_1_build_pop_subway_bus_park, bus_build_distance, how=\"left\")\n",
    "\n",
    "# save df\n",
    "df_1_build_pop_subway_bus_park_acc.to_csv(\"./data/df_500.csv\", index = False)\n",
    "\n",
    "df_1_build_pop_subway_bus_park_acc.to_csv(\"./data/df_500_kr.csv\", index = False, encoding=\"euc-kr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-luther",
   "metadata": {},
   "source": [
    "### df_100 수원시 데이터 추출\n",
    "- 인구정보와 유동인구 변수들은 수원시 데이터를 기준으로 추출 했기 때문에 따로 뽑지 않아도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "transsexual-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"gid_center\"] = 0\n",
    "center = final_df[\"geometry\"].centroid\n",
    "final_df[\"gid_center\"] = center"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-kentucky",
   "metadata": {},
   "source": [
    "- 토지이용특성 변수 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "respected-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100m 밀도 구하기\n",
    "gid_build = gpd.overlay(final_df, build_df, how = \"intersection\")\n",
    "\n",
    "gid_build[\"area\"] = 0\n",
    "area = gid_build[\"geometry\"].area\n",
    "gid_build[\"area\"] = area\n",
    "\n",
    "gid_build_area = gid_build.groupby([\"gid\", \"purpose\"])[\"area\"].agg(\"sum\").reset_index()\n",
    "\n",
    "\n",
    "gid_build_area_pivot = pd.pivot_table(gid_build_area, values = \"area\",\n",
    "                                      columns = \"purpose\", index = \"gid\").reset_index().fillna(0)\n",
    "\n",
    "\n",
    "gid_build_area_pivot[\"건물면적\"] = gid_build_area_pivot.iloc[:, 1:].sum(axis = 1)\n",
    "\n",
    "# 100m_area\n",
    "final_df_area = pd.merge(final_df, gid_build_area_pivot, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "inner-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server 이용시간을 고려해 저장\n",
    "bus_buffer.to_csv(\"./data/bus_buffer.csv\", index = False)\n",
    "bus_point.to_csv(\"./data/bus_point.csv\", index = False)\n",
    "build_df.to_csv(\"./data/build_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-criterion",
   "metadata": {},
   "source": [
    "- 지하철역 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "improved-vampire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지하철\n",
    "gid_sub = gpd.sjoin(final_df_area.loc[:, [\"gid\", \"geometry\"]], df_8, how = \"inner\")\n",
    "gid_sub_count = gid_sub[\"gid\"].value_counts().reset_index().rename({\"index\":\"gid\", \"gid\":\"지하철역수\"}, axis = 1)\n",
    "final_df_area_subway = pd.merge(final_df_area, gid_sub_count, how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-destruction",
   "metadata": {},
   "source": [
    "- 버스정류장 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "respected-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버스\n",
    "gid_bus = gpd.sjoin(final_df_area.loc[:, [\"gid\", \"geometry\"]], bus_point, how = \"inner\").reset_index(drop = True)\n",
    "gid_bus_count = gid_bus[\"gid\"].value_counts().reset_index().rename({\"index\":\"gid\", \"gid\":\"버스정류장수\"}, axis = 1)\n",
    "gid_bus = gpd.sjoin(final_df_area.loc[:, [\"gid\", \"geometry\"]], bus_point, how = \"inner\").reset_index(drop = True)\n",
    "final_df_area_subway_bus = pd.merge(final_df_area_subway, gid_bus_count, how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-pleasure",
   "metadata": {},
   "source": [
    "- 주차장 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bigger-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주차장 df_12\n",
    "gid_park = gpd.sjoin(final_df_area.loc[:, [\"gid\", \"geometry\"]], df_12, how = \"inner\").reset_index(drop = True)\n",
    "gid_park_count = gid_park[\"gid\"].value_counts().reset_index().rename({\"index\":\"gid\", \"gid\":\"주차장수\"}, axis = 1)\n",
    "final_df_area_subway_bus_park = pd.merge(final_df_area_subway_bus, gid_park_count, how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-unemployment",
   "metadata": {},
   "source": [
    "- 접근성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "electric-airport",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95991/95991 [01:25<00:00, 1116.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# 접근성\n",
    "gid_build_center = gpd.sjoin(final_df_area.loc[:, [\"gid\", \"geometry\", \"gid_center\"]], build_df, op = \"intersects\")\n",
    "\n",
    "gid_build_center[\"distance\"] = 0\n",
    "gid_build_center.reset_index(drop = True, inplace = True)\n",
    "\n",
    "distance = gid_build_center[\"gid_center\"].distance(gid_build_center[\"center\"])\n",
    "gid_build_center[\"distance\"] = distance\n",
    "    \n",
    "gid_build_center_dist = gid_build_center.groupby(\"gid\")[\"distance\"].agg(\"mean\").reset_index()\n",
    "final_df_area_subway_bus_park_acc = pd.merge(final_df_area_subway_bus_park, gid_build_center_dist, how = \"left\")\n",
    "final_df_area_subway_bus_park_acc.to_csv(\"./data/df_100.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-focus",
   "metadata": {},
   "source": [
    "### df_100_to_500 훈련데이터 추출\n",
    "- 100m 기준점 기준 500m 버퍼 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# server 끊어졌을 때 다시실행\n",
    "final_df = pd.read_csv(\"유동인구_인구정보_결합.csv\")\n",
    "df_gid_pop = pd.read_csv(\"df_gid_pop.csv\")\n",
    "final_df = gpd.GeoDataFrame(final_df)\n",
    "df_gid_pop = gpd.GeoDataFrame(df_gid_pop)\n",
    "def str_to_geo(x):\n",
    "    a = shapely.wkt.loads(x)\n",
    "    return a\n",
    "\n",
    "final_df[\"geometry\"] = final_df[\"geometry\"].apply(lambda x: str_to_geo(x))\n",
    "df_gid_pop[\"geometry\"] = df_gid_pop[\"geometry\"].apply(lambda x: str_to_geo(x))\n",
    "df_gid_pop[\"gid_center\"] = df_gid_pop[\"gid_center\"].apply(lambda x: str_to_geo(x))\n",
    "df_gid_pop[\"gid_center\"] = df_gid_pop[\"gid_center\"].astype(\"geometry\")\n",
    "\n",
    "df_gid_pop_coef = df_gid_pop.loc[:, [\"gid_1\", \"gid_center\"]]\n",
    "final_df[\"gid_center\"] = 0\n",
    "center = final_df[\"geometry\"].centroid\n",
    "final_df[\"gid_center\"] = center\n",
    "\n",
    "gid_with_rink = df_gid_pop_coef[\"gid_1\"].unique()\n",
    "\n",
    "# gid index화 후 loc로 뽑기\n",
    "df_gid = final_df.set_index(\"gid\").loc[gid_with_rink, :].reset_index()\n",
    "\n",
    "# 1m\n",
    "coor_1m = (1/88.74/1000)\n",
    "\n",
    "# gid격자 buffer화\n",
    "df_gid[\"buffer\"] = 0\n",
    "df_gid_buffer = df_gid[\"gid_center\"].buffer(coor_1m * 500)\n",
    "df_gid[\"buffer\"] = df_gid_buffer\n",
    "\n",
    "# df_gid의 기준 추출\n",
    "df_gid_crit = df_gid.loc[:, [\"gid\", \"buffer\"]].rename({\"buffer\":\"geometry\"}, axis = 1)\n",
    "\n",
    "build_df = pd.read_csv(\"./data/build_df.csv\")\n",
    "build_df = gpd.GeoDataFrame(build_df)\n",
    "build_df[\"geometry\"] = build_df[\"geometry\"].apply(lambda x: str_to_geo(x))\n",
    "build_df[\"center\"] = build_df[\"center\"].apply(lambda x: str_to_geo(x))\n",
    "build_df[\"center\"] = build_df[\"center\"].astype(\"geometry\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-discount",
   "metadata": {},
   "source": [
    "- 버스정류장은 도로가 있는 지역에 설치가 가능하므로 df_100 수원시 데이터와 도로 데이터를 결합하여 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df와 도로 데이터 sjoin\n",
    "a = gpd.sjoin(final_df, gpd.GeoDataFrame(road_transport_geo), how = \"inner\")\n",
    "\n",
    "# sjoin gid 뽑기\n",
    "gid_with_rink = a[\"gid\"].unique()\n",
    "\n",
    "# gid index화 후 loc로 뽑기\n",
    "df_gid = final_df.set_index(\"gid\").loc[gid_with_rink, :].reset_index()\n",
    "\n",
    "# gid격자 buffer화\n",
    "df_gid[\"buffer\"] = 0\n",
    "df_gid_buffer = df_gid[\"gid_center\"].buffer(coor_1m * 500)\n",
    "df_gid[\"buffer\"] = df_gid_buffer\n",
    "\n",
    "# df_gid의 기준 추출\n",
    "df_gid_crit = df_gid.loc[:, [\"gid\", \"buffer\"]].rename({\"buffer\":\"geometry\"}, axis = 1)\n",
    "\n",
    "# df_gid overlay pop\n",
    "df_gid_pop = gpd.overlay(df_gid_crit, final_df, how = \"intersection\")\n",
    "\n",
    "# csv 파일 저장\n",
    "df_gid_pop.to_csv(\"df_gid_pop.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-london",
   "metadata": {},
   "source": [
    "- 유동인구- 인구정보 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "outstanding-poland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 252.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# gid 별 area 구하기\n",
    "final_df[\"area\"] = final_df[\"geometry\"].area\n",
    "\n",
    "# coef 변수 생성\n",
    "df_gid_pop[\"coef\"] = 0\n",
    "\n",
    "# gid별 실제 area 구하기\n",
    "a = pd.merge(df_gid_pop.loc[:, [\"gid_1\", \"old\"]].rename({\"gid_1\":\"gid\"}, axis = 1), \n",
    "             final_df.loc[:, [\"gid\", \"area\"]], how = \"left\")\n",
    "\n",
    "# coef 가중치 구하기\n",
    "df_gid_pop[\"coef\"] = df_gid_pop[\"geometry\"].area / a[\"area\"]\n",
    "\n",
    "# 계산 필요 변수 유동인구는 시간대별만 활용\n",
    "df_gid_pop_col = df_gid_pop.iloc[:, 2:-4].columns.values\n",
    "\n",
    "\n",
    "# 가중치 부여\n",
    "for idx in tqdm.tqdm(range(len(df_gid_pop_col))):\n",
    "    df_gid_pop[df_gid_pop_col[idx]] = df_gid_pop[df_gid_pop_col[idx]].mul(df_gid_pop[\"coef\"])\n",
    "    \n",
    "# 저장\n",
    "df_gid_pop.to_csv(\"df_gid_pop_coef.csv\", index = False)\n",
    "\n",
    "# 그룹화\n",
    "df_gid_pop_coef_group = df_gid_pop.groupby(\"gid_1\")[df_gid_pop_col].agg('sum').reset_index().rename({\"gid_1\":\"gid\"}, axis = 1)\n",
    "\n",
    "# 저장\n",
    "df_gid_pop_coef_group.to_csv(\"df_gid_pop_coef_group.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-warrior",
   "metadata": {},
   "source": [
    "- 지하철역 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "significant-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지하철\n",
    "geo = gpd.points_from_xy(df_8.lon, df_8.lat)\n",
    "df_8[\"geometry\"] = geo\n",
    "\n",
    "gid_sub = gpd.sjoin(df_gid_crit, df_8, how = \"inner\")\n",
    "gid_sub_count = gid_sub[\"gid\"].value_counts().reset_index().rename({\"index\":\"gid\", \"gid\":\"지하철역수\"}, axis = 1)\n",
    "df_gid_pop_coef_group_subway = pd.merge(df_gid_pop_coef_group, gid_sub_count, how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-present",
   "metadata": {},
   "source": [
    "- 버스정류장 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "elementary-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버스\n",
    "bus_point = gpd.GeoDataFrame(pd.read_csv(\"./data/bus_point.csv\"))\n",
    "bus_point[\"geometry\"] = bus_point[\"geometry\"].apply(lambda x: str_to_geo(x))\n",
    "\n",
    "gid_bus = gpd.sjoin(df_gid_crit, bus_point, how = \"inner\").reset_index(drop = True)\n",
    "gid_bus_count = gid_bus[\"gid\"].value_counts().reset_index().rename({\"index\":\"gid\", \"gid\":\"버스정류장수\"}, axis = 1)\n",
    "df_gid_pop_coef_group_subway_bus = pd.merge(df_gid_pop_coef_group_subway, gid_bus_count, how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-programming",
   "metadata": {},
   "source": [
    "- 지하철역 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "periodic-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주차장 df_12\n",
    "geo = gpd.points_from_xy(df_12.lon, df_12.lat)\n",
    "df_12[\"geometry\"] = geo\n",
    "\n",
    "gid_park = gpd.sjoin(df_gid_crit, df_12, how = \"inner\").reset_index(drop = True)\n",
    "gid_park_count = gid_park[\"gid\"].value_counts().reset_index().rename({\"index\":\"gid\", \"gid\":\"주차장수\"}, axis = 1)\n",
    "df_gid_pop_coef_group_subway_bus_park = pd.merge(df_gid_pop_coef_group_subway_bus, gid_park_count, how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-dance",
   "metadata": {},
   "source": [
    "- 접근성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "czech-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 접근성\n",
    "df_gid_crit[\"gid_center\"] = df_gid_crit[\"geometry\"].centroid\n",
    "gid_build_center = gpd.sjoin(df_gid_crit, build_df, op = \"intersects\")\n",
    "\n",
    "gid_build_center[\"distance\"] = 0\n",
    "gid_build_center.reset_index(drop = True, inplace = True)\n",
    "\n",
    "distance = gid_build_center[\"gid_center\"].distance(gid_build_center[\"center\"])\n",
    "gid_build_center[\"distance\"] = distance\n",
    "    \n",
    "gid_build_center_dist = gid_build_center.groupby(\"gid\")[\"distance\"].agg(\"mean\").reset_index()\n",
    "df_gid_pop_coef_group_subway_bus_park_acc = pd.merge(df_gid_pop_coef_group_subway_bus_park, gid_build_center_dist, how = \"left\")\n",
    "df_gid_pop_coef_group_subway_bus_park_acc.to_csv(\"./data/df_100_to_500.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-necessity",
   "metadata": {},
   "source": [
    "- 토지이용특성 변수 추출\n",
    "    * 연산이 오래 걸리기 때문에 서버 이용시간을 고려해서 indexing 해서 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ruled-dependence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 596.1591682434082\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gid_buffer_inter_1 = gpd.overlay(df_gid_crit[:1000], build_df, how = \"intersection\")\n",
    "\n",
    "gid_buffer_inter_1.to_csv(\"gid_buffer_inter_1.csv\", index = False)\n",
    "end = time.time()\n",
    "print(\"time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "shared-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 한거 불러오기\n",
    "gid_buffer_inter_1 = pd.read_csv(\"gid_buffer_inter_1.csv\")\n",
    "gid_buffer_inter_1 = gpd.GeoDataFrame(gid_buffer_inter_1)\n",
    "gid_buffer_inter_1[\"geometry\"] = gid_buffer_inter_1[\"geometry\"].apply(lambda x: str_to_geo(x))\n",
    "\n",
    "gid_buffer_inter_1[\"area\"] = gid_buffer_inter_1[\"geometry\"].area\n",
    "gid_area_1 = gid_buffer_inter_1.groupby([\"gid\", \"purpose\"])[\"area\"].agg(\"sum\").reset_index()\n",
    "\n",
    "gid_area_1_pivot = pd.pivot_table(data = gid_area_1, index = \"gid\", columns=\"purpose\", values = \"area\")\n",
    "gid_area_1_pivot = gid_area_1_pivot.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "impressed-impossible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 913.8244581222534\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gid_buffer_inter_2 = gpd.overlay(df_gid_crit[1000:2000], build_df, how = \"intersection\")\n",
    "gid_buffer_inter_2.to_csv(\"gid_buffer_inter_2.csv\", index = False)\n",
    "end = time.time()\n",
    "print(\"time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "decimal-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "gid_buffer_inter_2 = pd.read_csv(\"gid_buffer_inter_2.csv\")\n",
    "gid_buffer_inter_2 = gpd.GeoDataFrame(gid_buffer_inter_2)\n",
    "gid_buffer_inter_2[\"geometry\"] = gid_buffer_inter_2[\"geometry\"].apply(lambda x: str_to_geo(x))\n",
    "\n",
    "gid_buffer_inter_2[\"area\"] = gid_buffer_inter_2[\"geometry\"].area\n",
    "gid_area_2 = gid_buffer_inter_2.groupby([\"gid\", \"purpose\"])[\"area\"].agg(\"sum\").reset_index()\n",
    "\n",
    "gid_area_2_pivot = pd.pivot_table(data = gid_area_2, index = \"gid\", columns=\"purpose\", values = \"area\")\n",
    "gid_area_2_pivot = gid_area_2_pivot.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "varying-landscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 2098.75452709198\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gid_buffer_inter_3 = gpd.overlay(df_gid_crit[2000:3000], build_df, how = \"intersection\")\n",
    "gid_buffer_inter_3.to_csv(\"gid_buffer_inter_3.csv\", index = False)\n",
    "end = time.time()\n",
    "print(\"time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "colored-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "gid_buffer_inter_3 = pd.read_csv(\"gid_buffer_inter_3.csv\")\n",
    "gid_buffer_inter_3 = gpd.GeoDataFrame(gid_buffer_inter_3)\n",
    "gid_buffer_inter_3[\"geometry\"] = gid_buffer_inter_3[\"geometry\"].apply(lambda x: str_to_geo(x))\n",
    "\n",
    "gid_buffer_inter_3[\"area\"] = gid_buffer_inter_3[\"geometry\"].area\n",
    "gid_area_3 = gid_buffer_inter_3.groupby([\"gid\", \"purpose\"])[\"area\"].agg(\"sum\").reset_index()\n",
    "\n",
    "gid_area_3_pivot = pd.pivot_table(data = gid_area_3, index = \"gid\", columns=\"purpose\", values = \"area\")\n",
    "gid_area_3_pivot = gid_area_3_pivot.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "signal-jenny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 1640.516138792038\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gid_buffer_inter_4 = gpd.overlay(df_gid_crit[3000:4000], build_df, how = \"intersection\")\n",
    "gid_buffer_inter_4.to_csv(\"gid_buffer_inter_4.csv\", index = False)\n",
    "end = time.time()\n",
    "print(\"time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "blond-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "gid_buffer_inter_4 = pd.read_csv(\"gid_buffer_inter_4.csv\")\n",
    "gid_buffer_inter_4 = gpd.GeoDataFrame(gid_buffer_inter_4)\n",
    "gid_buffer_inter_4[\"geometry\"] = gid_buffer_inter_4[\"geometry\"].apply(lambda x: str_to_geo(x))\n",
    "\n",
    "gid_buffer_inter_4[\"area\"] = gid_buffer_inter_4[\"geometry\"].area\n",
    "gid_area_4 = gid_buffer_inter_4.groupby([\"gid\", \"purpose\"])[\"area\"].agg(\"sum\").reset_index()\n",
    "\n",
    "gid_area_4_pivot = pd.pivot_table(data = gid_area_4, index = \"gid\", columns=\"purpose\", values = \"area\")\n",
    "gid_area_4_pivot = gid_area_4_pivot.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subtle-fitness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 1008.5128085613251\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gid_buffer_inter_5 = gpd.overlay(df_gid_crit[4000:], build_df, how = \"intersection\")\n",
    "gid_buffer_inter_5.to_csv(\"gid_buffer_inter_5.csv\", index = False)\n",
    "end = time.time()\n",
    "print(\"time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "latin-affiliation",
   "metadata": {},
   "outputs": [],
   "source": [
    "gid_buffer_inter_5 = pd.read_csv(\"gid_buffer_inter_5.csv\")\n",
    "gid_buffer_inter_5 = gpd.GeoDataFrame(gid_buffer_inter_5)\n",
    "gid_buffer_inter_5[\"geometry\"] = gid_buffer_inter_5[\"geometry\"].apply(lambda x: str_to_geo(x))\n",
    "\n",
    "gid_buffer_inter_5[\"area\"] = gid_buffer_inter_5[\"geometry\"].area\n",
    "gid_area_5 = gid_buffer_inter_5.groupby([\"gid\", \"purpose\"])[\"area\"].agg(\"sum\").reset_index()\n",
    "\n",
    "gid_area_5_pivot = pd.pivot_table(data = gid_area_5, index = \"gid\", columns=\"purpose\", values = \"area\")\n",
    "gid_area_5_pivot = gid_area_5_pivot.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "heavy-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "gid_area = pd.concat([gid_area_1_pivot, gid_area_2_pivot, gid_area_3_pivot,\n",
    "          gid_area_4_pivot, gid_area_5_pivot]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "rational-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "gid_area = gid_area.fillna(0)\n",
    "gid_area[\"건물면적\"] = gid_area.iloc[:, 1:].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "restricted-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100_to_500 = pd.read_csv(\"./data/df_100_to_500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "convertible-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gid_pop_coef_group_subway_bus_park_acc_build = pd.merge(df_100_to_500, gid_area, on=\"gid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "demanding-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gid_pop_coef_group_subway_bus_park_acc_build.to_csv(\"./data/df_100_to_500.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection을 위해 buffer slicing 후 geometry로 컬럼명 변경\n",
    "df_1_area = df_1.loc[:, [\"정류장ID\", \"buffer\"]].rename({\"buffer\":\"geometry\"}, axis = 1)\n",
    "\n",
    "# df_1_area를 기준으로 buil_df intersection\n",
    "bus_with_build_area_df = gpd.overlay(df_1_area, build_df, how = \"intersection\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 100_to_500 기준으로 buil_df intersection\n",
    "gid_buffer_inter = gpd.overlay(df_gid_crit, build_df, how = \"intersection\")\n",
    "\n",
    "# 건물면적 구하기\n",
    "bus_with_build_area_df[\"area\"] = bus_with_build_area_df.area\n",
    "\n",
    "# 정류장 ID와 건물분류별 면적 합하기\n",
    "build_area = bus_with_build_area_df.groupby([\"정류장ID\", \"purpose\"])[\"area\"].agg(\"sum\").reset_index()\n",
    "\n",
    "# pivot table 활용하여 정류장ID별 건물불류 변수 table 생성\n",
    "table = pd.pivot_table(build_area, values = \"area\", index = \"정류장ID\", columns = \"purpose\").reset_index()\n",
    "\n",
    "# 결측치 처리\n",
    "table = table.fillna(0)\n",
    "\n",
    "# # 500m 버퍼 내의 면적을 구하기 위해 500m 버퍼 면적 구하기(면적)\n",
    "# denominator = df_1_area[df_1_area[\"정류장ID\"] == '201000266'].area.values[0]\n",
    "\n",
    "# #  intersection / 500m 면적\n",
    "# # table.iloc[:, 1:] = table.iloc[:, 1:].apply(lambda x: x / denominator)\n",
    "\n",
    "# 버퍼 내 전체 건물 면적 구하기\n",
    "table[\"건물면적\"] = table.iloc[:, 1:].sum(axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
